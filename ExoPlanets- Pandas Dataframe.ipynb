{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-yRjeBfrIzI"
      },
      "source": [
        "# Hunting Exoplanets In Space - Pandas DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb6GsywkBTPn"
      },
      "source": [
        "\n",
        "In the process of creating Pandas DataFrames, we will see how NASA finds the exoplanets in the universe. There are deep Physical and mathematical theories on exploring exoplanets in the space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-zCMmreBUaH"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdmZPtYSn7kA"
      },
      "source": [
        "\n",
        "\n",
        "### Finding Exoplanets Principle\n",
        "\n",
        "There are billions of galaxies in the universe. These galaxies have millions of stars. One such galaxy is the Milky-way galaxy in which our solar system exists. The solar system has a star called Sun which has its own light. There are 8 planets in our solar system orbiting around the Sun. Similar to this, in some other galaxy there would be a star and probably a planet would be revolving around that star.\n",
        "\n",
        "Long back, NASA placed a telescope called Kepler telescope in the space. This telescope is used to measure the brightness of the stars in the far-distant galaxies.\n",
        "\n",
        "\n",
        "<img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/whitehat-ds-datasets/kepler-exoplanets-dataset/kepler-space-telescope.jpg' width=\"800\">\n",
        "\n",
        "*Image credits: https://www.nasa.gov/feature/ames/kepler/nasa-s-kepler-confirms-100-exoplanets-during-its-k2-mission*\n",
        "\n",
        "Whenever a planet, while orbiting its star, comes in between the telescope and the star, the brightness of the star recorded by the telescope is lower whereas when the planet goes behind the star, the brightness of the light recorded by the telescope is higher.\n",
        "\n",
        "This method of detecting exoplanets in far-distant galaxies through the brightness of the light emitted by a star is called the **Transit Method**.\n",
        "\n",
        "Essentially, if we plot the brightness on the vertical axis and the time on the horizontal axis, then we will see that the brightness of the star recorded by the telescope increases and decreases periodically. Thus, in the graph, we will notice a wave-like pattern. This indicates that the star definitely has at least one planet.\n",
        "\n",
        "<img src = 'https://s3-whjr-v2-prod-bucket.whjr.online/99a90115-148e-45c6-b9b0-4ac4a5db4e18.gif' width=500 >\n",
        "\n",
        "\n",
        "\n",
        "The image below shows some of the exoplanets (Kepler 4b to Kepler 8b) discovered by the Kepler space telescope. We can see the brightness level radiated by the star for each planet. The Flux values on the vertical axis represent the brightness level of the star.\n",
        "\n",
        "<img src = 'https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/whitehat-ds-datasets/kepler-exoplanets-dataset/transit-method.jpg' width='800'>\n",
        "\n",
        "*Image credits: https://www.nasa.gov/content/light-curves-of-keplers-first-5-discoveries*\n",
        "\n",
        "As we can see in the image above, the bigger the planet (Kepler 6b), deeper the dip in the brightness level. And, the longer the orbital period of a planet, broader is the width of the dip (Kepler 7b). Kepler 7b has the greatest orbital period of 4.9 days among these 5 planets.\n",
        "\n",
        "So, this is how NASA finds a planet beyond our solar system. Now, let's use Kepler space telescope dataset to create a Pandas DataFrame in order to find out which stars beyond our solar system have a planet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq9mAtEg9cpZ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "file_to_load = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "DhJBtNcJihGl",
        "outputId": "b3b81680-8955-4a7b-ace8-198a048b2ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6345d36f-6774-48fa-94e7-5c5f945da4fc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6345d36f-6774-48fa-94e7-5c5f945da4fc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwzryU6Zie33"
      },
      "source": [
        "#### Loading CSV File\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjScdqmQstFg"
      },
      "source": [
        "# Teacher Action: Read a 'csv' file using the 'read_csv()' function. Also, display the first 5 rows of the DataFrame using the 'head()' function.\n",
        "# First of all we have to import the Pandas module with pd as an alias (or nickname).\n",
        "import pandas as pd\n",
        "\n",
        "exo_train_df = pd.read_csv('exoTrain.csv')\n",
        "exo_train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4RGB9jb9hym"
      },
      "source": [
        "We have created a Pandas DataFrame for the `exoTrain.csv` file and stored it in the `exo_train_df` variable.\n",
        "\n",
        "Now, we will create a DataFrame for the `exoTest.csv` file and store it in a variable called `exo_test_df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sys1jcw2jpF3"
      },
      "source": [
        "# Reading the 'exoTest.csv' file and display its first 5 rows using the 'head()' function.\n",
        "exo_test_df = pd.read_csv('https://s3-student-datasets-bucket.whjr.online/whitehat-ds-datasets/kepler-exoplanets-dataset/exoTest.csv')\n",
        "exo_test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNIuF-oKkExp"
      },
      "source": [
        "The two DataFrames have exactly the same type of data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aGcwb3Ax10u"
      },
      "source": [
        "# Find the number of rows and columns in the 'exo_train_df' DataFrame.\n",
        "exo_train_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQXojZA6m1Oo"
      },
      "source": [
        "So, there are 5087 rows and 3198 columns in the `exo_train_df` DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77zf3wvMnjNB"
      },
      "source": [
        "# Find the number of rows and columns in the 'exo_test_df' DataFrame.\n",
        "exo_test_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afcKyO4An1tN"
      },
      "source": [
        "There are 570 rows and 3198 columns in the `exo_test_df` DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW6N0e0dn9jq"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kr-OIofEvrC"
      },
      "source": [
        "#### Check For The Missing Values^\n",
        "\n",
        "In most of the cases, we do not get complete datasets. They either have some values missing from the rows and columns or they do not have standardized values.\n",
        "\n",
        "So, before going ahead with the analysis, it is a good idea to check whether the dataset has any missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p28lXAqoFQMe"
      },
      "source": [
        "# Check for the missing values using the 'isnull()' function.\n",
        "exo_train_df.isnull()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSubPWuvFZ0d"
      },
      "source": [
        "There are $5087\\times3198=16268226$ values in the DataFrame. It is not feasible to check so many values manually. So, we need a better approach to check for missing values.\n",
        "\n",
        "We can call the `sum()` function on the `exo_train_df.isnull()` statement. It will return the sum of `True` values for every column in a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSthlUG5FYLG"
      },
      "source": [
        "# Use the 'sum()' function to find the total number of True values in each column.\n",
        "exo_train_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNuRR1NjHh99"
      },
      "source": [
        "We can see that a lot of columns have `0` missing values. But still, we cannot manually see whether all the columns have missing values or not because the list of columns is too long to be seen in this notebook. There are `3198` columns to search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-2gSCVkHiag"
      },
      "source": [
        "# View all the columns in the 'exo_train_df' DataFrame.\n",
        "exo_train_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2EzheZ4H_lh"
      },
      "source": [
        "\n",
        "We, again, need a better approach. We will create a variable called `num_missing_values` to store the total number of values that are missing. Then, we will iterate through each column and within each column, we will iterate through each item to check for the missing values. If the `isnull()` function for a column returns `True`, then we will increase the value of the `num_missing_values` by `1` else we will not do anything."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHjOAaq-IU_c"
      },
      "source": [
        "# Iterate through the 'exo_train_df' DataFrame to find the total number of missing values.\n",
        "num_missing_values = 0\n",
        "# Here, we have created the num_missing_values which will store all the number of missing values in the DataFrame.\n",
        "\n",
        "# Now, we will iterate through every column in the DataFrame, then will iterate through every item in each column.\n",
        "for column in exo_train_df.columns:\n",
        "  for item in exo_train_df[column].isnull():\n",
        "    if item == True:\n",
        "      num_missing_values += 1\n",
        "\n",
        "num_missing_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tts_SnCSJW2z"
      },
      "source": [
        "As seen, there are no missing values in the DataFrame because the final value of the `num_missing_values` is `0`.\n",
        "\n",
        "Now let's find the number of non missing values by replacing `True` with `False` in the above code and store it in variable `non_missing_values`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH9-fPPYJWOQ"
      },
      "source": [
        "# In the above code replace 'True' with 'False' and get the number of non missing values.\n",
        "non_missing_values = 0\n",
        "for column in exo_train_df.columns:\n",
        "  for item in exo_train_df[column].isnull():\n",
        "    if item == False:\n",
        "      non_missing_values += 1\n",
        "\n",
        "non_missing_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufUqq0kMJotW"
      },
      "source": [
        "As we can see, the output is 16,268,226. It is the sum of all the values which are False. That means there are no missing values because the total number of values in the `exo_train_df` is 16,268,226 which is exactly the same as the total number of non-missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZDCZAklQ2Fe"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llwHgQbDLLT8"
      },
      "source": [
        "#### Slicing A DataFrame Using The `iloc[]` Function\n",
        "\n",
        " We want to plot the scatter plots and line plots for 6 stars. For each of these stars we will create a Pandas series which will have the brightness levels starting from `FLUX.1` to `FLUX.3197`.\n",
        "\n",
        " Effectively, we need to create 6 Pandas series.\n",
        "\n",
        "Let's create a Pandas series for the first star in the `exo_train_df`. Let's store the series in a variable called `star_0`. To do this, we need to use the `iloc` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bERYJF3JpFR"
      },
      "source": [
        "# Create a Pandas series from a Pandas DataFrame using the 'iloc[]' function.\n",
        "star_0 = exo_train_df.iloc[0, :]\n",
        "star_0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gKra1lEMLji"
      },
      "source": [
        "# Using the 'iloc[]' function, create a Pandas series for the second star and storing it in a variable called 'star_1'.\n",
        "star_1 = exo_train_df.iloc[1, :]\n",
        "star_1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn8St5flM0k3"
      },
      "source": [
        "#Using the 'iloc[]' function, create a Pandas series for the third star and storing it in a variable called 'star_2'.\n",
        "star_2 = exo_train_df.iloc[2, :]\n",
        "star_2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgUmqwwGQfAq"
      },
      "source": [
        "We have created a Pandas series for each of the first three stars. Now, let's create the same for each of the last three stars in the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tIu89YeM5Ih"
      },
      "source": [
        "#Displaying the last 5 rows of the 'exo_train_df'\n",
        "exo_train_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dOssdOlM-Lz"
      },
      "source": [
        "# Creating a Pandas series for the last star\n",
        "star_5086 = exo_train_df.iloc[5086, :]\n",
        "star_5086.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07pOAWj_NBYM"
      },
      "source": [
        "# creating a Pandas series for the second-last star\n",
        "star_5085 = exo_train_df.iloc[5085, :]\n",
        "star_5085.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scFAkI-KNE3M"
      },
      "source": [
        "# creating a Pandas series for the third-last star\n",
        "star_5084 = exo_train_df.iloc[5084, :]\n",
        "star_5084.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}